---
title: 一致性哈希算法
date: 2019-03-27 16:18:48
tags:
categories: 数据结构
---

# 一致性哈希简介

一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点（Hot Spot）问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 

一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：

（1）平衡性（Balance）

平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。

（2）单调性（Monotonicity）

单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 

（3）分散性（Spread）

在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 

（4）负载（Load）

负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。

在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的`hash(object)%N`算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。

简单来说，在一个多节点的集群中，数据对象按照Hash算法分布到不同的机器节点上，简单的Hash算法如下：

    server = serverlist[hash(object)%serverlist.length]

这样的情况下，当有机器增加或删除时，所有的数据对象都被会重新Hash到不同的机器节点上。而一致性哈希算法就是为了解决这个问题的，当有机器节点增加或删除时，仅会影响到部分数据对象被Hash到不同的机器节点上，而大部分数据对象是不会被重新Hash的。

# 一致性哈希原理

（1）环形Hash空间概念

按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即`0~(2^32)-1`的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图：

![](/images/ds_dht_1_1.png)

（2）把数据对象通过hash算法映射到环上
现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。如下图：

    Hash(object1) = key1
    Hash(object2) = key2
    Hash(object3) = key3
    Hash(object4) = key4

![](/images/ds_dht_1_2.png)

（3）将机器节点通过hash算法映射到环上

在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。

假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中，其示意图如下：

    Hash(NODE1) = KEY1
    Hash(NODE2) = KEY2
    Hash(NODE3) = KEY3

![](/images/ds_dht_1_3.png)

通过上图可以看出对象与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。

备注：（2）和（3）使用的hash算法函数是一样的哦

# 一致性哈希算法下机器节点变更下数据迁移现象

普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。

（1）节点（机器）的删除

以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图：

![](/images/ds_dht_1_4.png)

（2）节点（机器）的添加

如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图：

![](/images/ds_dht_1_5.png)

通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。

# 一致性hash算法的应用

（1）在nginx的ngx_http_upstream_module模块中有一个`hash key [consistent]`的指令，就是哈希一致性算法的一个应用。当upstream组新增或下线了机器，一致性hash算法能保证尽量少的请求会被重新映射到其他机器上，从而保证机器增减时，缓存的命中率不会有非常大的波动。

（2）数据库的水平拆分时，可以考虑使用一致性Hash，避免后续扩展时，需要全局迁移数据。

（3）Redis集群也是采用的一致性哈希算法。

学习资料参考于：
https://blog.csdn.net/cywosp/article/details/23397179
https://www.jianshu.com/p/570dc8913c20
